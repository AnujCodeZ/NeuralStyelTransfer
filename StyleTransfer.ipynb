{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleTransfer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJriPX5odahK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPp-UXn0Gur9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Model \"\"\"\n",
        " \n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models\n",
        " \n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "import copy\n",
        " \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        " \n",
        "imsize = 512 if torch.cuda.is_available() else 128\n",
        " \n",
        "loader = transforms.Compose([transforms.Resize(imsize),\n",
        "                             transforms.ToTensor()])\n",
        "unloader = transforms.ToPILImage()\n",
        " \n",
        "class ContentLoss(nn.Module):\n",
        " \n",
        "  def __init__(self, target):\n",
        "    super().__init__()\n",
        " \n",
        "    self.target = target.detach()\n",
        " \n",
        "  def forward(self, input):\n",
        "    \n",
        "    self.loss = F.mse_loss(input, self.target)\n",
        " \n",
        "    return input\n",
        " \n",
        "def gram_matrix(input):\n",
        " \n",
        "  a, b, c, d = input.size()\n",
        "  features = input.view(a * b, c * d)\n",
        "  G = torch.mm(features, features.t())\n",
        " \n",
        "  return G.div(a * b * c * d)\n",
        " \n",
        "class StyleLoss(nn.Module):\n",
        " \n",
        "  def __init__(self, target_features):\n",
        "    super().__init__()\n",
        " \n",
        "    self.target = gram_matrix(target_features).detach()\n",
        "  \n",
        "  def forward(self, input):\n",
        " \n",
        "    G = gram_matrix(input)\n",
        "    self.loss = F.mse_loss(G, self.target)\n",
        " \n",
        "    return input\n",
        " \n",
        "cnn = models.vgg19(pretrained=True).features.to(device).eval()\n",
        " \n",
        "cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
        "cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
        " \n",
        "class Normalization(nn.Module):\n",
        "  \n",
        "  def __init__(self, mean, std):\n",
        "    super().__init__()\n",
        " \n",
        "    self.mean = torch.tensor(mean).view(-1, 1, 1)\n",
        "    self.std = torch.tensor(std).view(-1, 1, 1)\n",
        "  \n",
        "  def forward(self, img):\n",
        " \n",
        "    return (img - self.mean) / self.std\n",
        " \n",
        "content_layers_default = ['conv_4']\n",
        "style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4']\n",
        " \n",
        "def get_style_model_and_losses(\n",
        "    cnn, normalization_mean, normalization_std,\n",
        "    style_img, content_img,\n",
        "    content_layers=content_layers_default,\n",
        "    style_layers=style_layers_default):\n",
        "  \n",
        "  cnn = copy.deepcopy(cnn)\n",
        " \n",
        "  normalization = Normalization(normalization_mean, normalization_std)\\\n",
        "  .to(device)\n",
        " \n",
        "  content_losses = []\n",
        "  style_losses = []\n",
        " \n",
        "  model = nn.Sequential(normalization)\n",
        " \n",
        "  i = 0\n",
        "  for layer in cnn.children():\n",
        " \n",
        "    if isinstance(layer, nn.Conv2d):\n",
        " \n",
        "      i += 1\n",
        "      name = 'conv_{}'.format(i)\n",
        "    \n",
        "    elif isinstance(layer, nn.ReLU):\n",
        " \n",
        "      name = 'relu_{}'.format(i)\n",
        "      layer = nn.ReLU(inplace=False)\n",
        "    \n",
        "    elif isinstance(layer, nn.MaxPool2d):\n",
        " \n",
        "      name = 'pool_{}'.format(i)\n",
        "    \n",
        "    elif isinstance(layer, nn.BatchNorm2d):\n",
        " \n",
        "      name = 'bn_{}'.format(i)\n",
        "    \n",
        "    else:\n",
        " \n",
        "      raise RuntimeError('Unrecognized layer: {}'\\\n",
        "                         .format(layer.__class__.__name__))\n",
        " \n",
        "    model.add_module(name, layer)\n",
        " \n",
        "    if name in content_layers:\n",
        " \n",
        "      target = model(content_img).detach()\n",
        "      content_loss = ContentLoss(target)\n",
        "      model.add_module('content_loss_{}'.format(i), content_loss)\n",
        "      content_losses.append(content_loss)\n",
        "    \n",
        "    if name in style_layers:\n",
        " \n",
        "      target_feature = model(style_img).detach()\n",
        "      style_loss = StyleLoss(target_feature)\n",
        "      model.add_module('style_loss_{}'.format(i), style_loss)\n",
        "      style_losses.append(style_loss)\n",
        " \n",
        "  for i in range(len(model) - 1, -1, -1):\n",
        " \n",
        "    if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n",
        "      break\n",
        " \n",
        "  return model, style_losses, content_losses  \n",
        " \n",
        "def get_input_optimizer(input_img):\n",
        " \n",
        "  optimizer = optim.LBFGS([input_img.requires_grad_()])\n",
        " \n",
        "  return optimizer\n",
        " \n",
        "def run_style_transfer(\n",
        "    cnn, normalization_mean, normalization_std,\n",
        "    content_img, style_img, input_img, num_steps=300,\n",
        "    style_weight=1000000, content_weight=1):\n",
        "  \n",
        "  print('Building the style transfer model...')\n",
        "  model, style_losses, content_losses = get_style_model_and_losses(\n",
        "      cnn, normalization_mean, normalization_std,\n",
        "      style_img, content_img\n",
        "  )\n",
        " \n",
        "  print('Optimizing...')\n",
        "  optimizer = get_input_optimizer(input_img)\n",
        " \n",
        "  run = [0]\n",
        "  while run[0] <= num_steps:\n",
        " \n",
        "    def closure():\n",
        " \n",
        "      input_img.data.clamp_(0, 1)\n",
        " \n",
        "      optimizer.zero_grad()\n",
        " \n",
        "      model(input_img)\n",
        "      style_score = 0\n",
        "      content_score = 0\n",
        " \n",
        "      for sl in style_losses:\n",
        " \n",
        "        style_score += sl.loss\n",
        "      \n",
        "      for cl in content_losses:\n",
        " \n",
        "        content_score += cl.loss\n",
        "      \n",
        "      style_score *= style_weight\n",
        "      content_score *= content_weight\n",
        " \n",
        "      loss = style_score + content_score\n",
        "      loss.backward()\n",
        " \n",
        "      run[0] += 1\n",
        "      if run[0]%50 == 0:\n",
        " \n",
        "        print('run {}'.format(run))\n",
        "        print('Syle Loss: {:.4f} Content Loss: {:.4f}'.format(\n",
        "            style_score.item(), content_score.item()\n",
        "        ))\n",
        "        print()\n",
        "      \n",
        "      return style_score + content_score\n",
        "    \n",
        "    optimizer.step(closure)\n",
        "  \n",
        "  input_img.data.clamp_(0, 1)\n",
        " \n",
        "  return input_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As_Ct0QGo9OD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Preprocessing \"\"\"\n",
        "\n",
        "def make_square(im, min_size=imsize, fill_color=(255, 255, 255)):\n",
        "    x, y = im.size\n",
        "    size = max(min(x, y), min_size)\n",
        "    new_im = Image.new('RGB', (size, size), fill_color)\n",
        "    new_im.paste(im, (int((size - x) / 2), int((size - y) / 2)))\n",
        "    return new_im\n",
        "\n",
        "def load_from_pil(img):\n",
        "  image = loader(img).unsqueeze(0)\n",
        "  return image.to(device, torch.float)\n",
        " \n",
        "def preprocess(content, style):\n",
        " \n",
        "  content = Image.open(content)\n",
        "  style = Image.open(style)\n",
        " \n",
        "  content, style = make_square(content), make_square(style)\n",
        " \n",
        "  content, style = load_from_pil(content), load_from_pil(style)\n",
        " \n",
        "  return content, style"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjf2yQ_-Kvu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Model runner \"\"\"\n",
        " \n",
        "def run(content, style):\n",
        " \n",
        "  content_image, style_image = preprocess(content, style)\n",
        " \n",
        "  input_image = content_image.clone()\n",
        " \n",
        "  generated_image = run_style_transfer(cnn, \n",
        "                                       cnn_normalization_mean, cnn_normalization_std, \n",
        "                                       content_image, style_image, input_image)\n",
        "  image = generated_image.cpu().clone()\n",
        "  image = image.squeeze(0)\n",
        "  image = unloader(image)\n",
        " \n",
        "  image.save('generated.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm7oPTYiugEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Get frontend files \"\"\"\n",
        " \n",
        "!mkdir templates\n",
        "!mkdir static\n",
        "!cp gdrive/My\\ Drive/StyleTransfer/index.html templates/\n",
        "!cp gdrive/My\\ Drive/StyleTransfer/generated.html templates/\n",
        "!cp gdrive/My\\ Drive/StyleTransfer/style.css static/\n",
        "!cp gdrive/My\\ Drive/StyleTransfer/function.js static/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUCYxTKdOXlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Get public url \"\"\"\n",
        " \n",
        "!pip install pyngrok\n",
        "!ngrok authtoken xxxxx\n",
        "from pyngrok import ngrok\n",
        " \n",
        "public_url = ngrok.connect(port = '5000')\n",
        " \n",
        "print(public_url)\n",
        "\n",
        "ngrok.disconnect(public_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efuDsA1GfGFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Backend api \"\"\"\n",
        " \n",
        "from flask import Flask, request, render_template, url_for\n",
        "from PIL import Image\n",
        " \n",
        "app = Flask(__name__)\n",
        " \n",
        "@app.route('/')\n",
        "@app.route('/index')\n",
        "def index():\n",
        " \n",
        "    return render_template('index.html')\n",
        " \n",
        "@app.route('/program', methods=['GET', 'POST'])\n",
        "def program():\n",
        "    if request.method == 'POST':\n",
        "        if request.files:\n",
        " \n",
        "            content = request.files.get('file1','')\n",
        "            style = request.files.get('file2','')\n",
        "            run(content, style)\n",
        " \n",
        "    return render_template('index.html')\n",
        " \n",
        "@app.route('/generated', methods=['GET', 'POST'])\n",
        "def generated():\n",
        "    return render_template('generated.html', content='/static/generated.jpg')\n",
        " \n",
        "if __name__ == \"__main__\":\n",
        "    app.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkJdCjcwPYtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ngrok.kill()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}